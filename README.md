# jailbreak-gpt
 Code vulnerabilities analysis and correction using a jailbreaked LLM
