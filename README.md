# jailbreak-gpt
 Code vulnerabilities analysis and correction using a jailbreaked LLM

# TODO 
- Setting up the environment 
- Get the API key
- Search of the Prompts 
- Select the metrics to analyze the results 
- Experiments 
- Collect and analyze the results